"""
AI ì˜ˆì¸¡ ì„œë¹„ìŠ¤
ì‹¤ì œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì„œë¹„ìŠ¤
"""
from typing import Dict, List, Optional
import re

class PredictorService:
    """
    ë–¡ìƒ ì˜ˆì¸¡ ì„œë¹„ìŠ¤
    
    í˜„ì¬ëŠ” ê·œì¹™ ê¸°ë°˜ ë”ë¯¸ ë¡œì§ì´ë©°, 
    ì‹¤ì œë¡œëŠ” í•™ìŠµëœ XGBoost/LightGBM ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì‚¬ìš©
    """
    
    def __init__(self):
        # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ ëª¨ë¸ íŒŒì¼(.pkl)ì„ ë¡œë“œ
        # self.model = joblib.load('path/to/model.pkl')
        self.beauty_keywords = {
            'ì˜¬ë¦¬ë¸Œì˜': 0.35,
            'ì‹ ìƒ': 0.28,
            'ë‚´ëˆë‚´ì‚°': 0.23,
            'GRWM': 0.20,
            'ë¦¬ë·°': 0.18,
            'ì¶”ì²œí…œ': 0.22,
            'í¼ìŠ¤ë„ì»¬ëŸ¬': 0.19,
            'ì¿¨í†¤': 0.15,
            'ì›œí†¤': 0.15,
            'í‹´íŠ¸': 0.12,
            'ë¦½ìŠ¤í‹±': 0.12,
            'íŒŒìš´ë°ì´ì…˜': 0.14,
            'ì„¸ì¼': 0.25,
            'í• ì¸': 0.20
        }
    
    def extract_features(self, title: str, description: Optional[str], tags: Optional[List[str]]) -> Dict:
        """
        í…ìŠ¤íŠ¸ì—ì„œ í”¼ì²˜ ì¶”ì¶œ
        """
        features = {}
        
        # ì œëª© ê¸¸ì´
        features['title_length'] = len(title)
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        text = title.lower()
        if description:
            text += " " + description.lower()
        
        for keyword, weight in self.beauty_keywords.items():
            if keyword.lower() in text:
                features[f'keyword_{keyword}'] = weight
        
        # íŠ¹ìˆ˜ë¬¸ì/ì´ëª¨ì§€ ì‚¬ìš© ì—¬ë¶€
        features['has_emoji'] = 1 if re.search(r'[^\w\s,.]', title) else 0
        
        # ìˆ«ì í¬í•¨ ì—¬ë¶€ (ì˜ˆ: "10ê°€ì§€", "3ë¶„")
        features['has_number'] = 1 if re.search(r'\d+', title) else 0
        
        return features
    
    def predict(self, title: str, description: Optional[str] = None, tags: Optional[List[str]] = None) -> Dict:
        """
        ë–¡ìƒ í™•ë¥  ì˜ˆì¸¡
        """
        # í”¼ì²˜ ì¶”ì¶œ
        features = self.extract_features(title, description, tags)
        
        # ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ëª¨ë¸.predict()ë¥¼ ì‚¬ìš©)
        base_score = 40.0  # ê¸°ë³¸ ì ìˆ˜
        
        # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ í•©ì‚°
        keyword_boost = sum([v for k, v in features.items() if k.startswith('keyword_')]) * 100
        
        # ê¸°íƒ€ í”¼ì²˜ ë³´ë„ˆìŠ¤
        if features.get('has_number'):
            keyword_boost += 5
        if features.get('has_emoji'):
            keyword_boost += 3
        
        # ìµœì¢… í™•ë¥  ê³„ì‚°
        probability = min(base_score + keyword_boost, 95.0)  # ìµœëŒ€ 95%
        
        # ë–¡ìƒ ì—¬ë¶€ íŒì • (70% ì´ìƒ)
        is_viral = probability >= 70.0
        
        # ê°€ì´ë“œë¼ì¸ ìƒì„±
        guideline = self._generate_guideline(features, probability)
        
        # ì£¼ìš” ì˜í–¥ ìš”ì¸
        top_features = [
            {"feature": k, "impact": v}
            for k, v in features.items()
            if k.startswith('keyword_')
        ]
        top_features = sorted(top_features, key=lambda x: x['impact'], reverse=True)[:3]
        
        return {
            "probability": round(probability, 1),
            "is_viral": is_viral,
            "guideline": guideline,
            "top_features": top_features,
            "features": features
        }
    
    def _generate_guideline(self, features: Dict, probability: float) -> str:
        """
        ê°œì¸í™”ëœ ê°€ì´ë“œë¼ì¸ ìƒì„±
        """
        guidelines = []
        
        # í™•ë¥ ì— ë”°ë¥¸ ê¸°ë³¸ ë©”ì‹œì§€
        if probability >= 80:
            guidelines.append("ğŸ‰ ë§¤ìš° ë†’ì€ ì„±ê³µ í™•ë¥ ì…ë‹ˆë‹¤!")
        elif probability >= 70:
            guidelines.append("âœ¨ ì¢‹ì€ ì„±ê³µ ê°€ëŠ¥ì„±ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
        elif probability >= 50:
            guidelines.append("ğŸ’¡ ëª‡ ê°€ì§€ë§Œ ê°œì„ í•˜ë©´ ì„±ê³µ í™•ë¥ ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            guidelines.append("ğŸ“ ì œëª©ê³¼ ë‚´ìš©ì„ ë‹¤ìŒê³¼ ê°™ì´ ê°œì„ í•´ë³´ì„¸ìš”.")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¡°ì–¸
        has_keywords = [k.replace('keyword_', '') for k in features.keys() if k.startswith('keyword_')]
        
        if has_keywords:
            guidelines.append(f"\nâœ… ì¢‹ì€ í‚¤ì›Œë“œ: {', '.join(has_keywords[:3])}")
        
        # ê°œì„  ì œì•ˆ
        missing_keywords = []
        if 'keyword_ì˜¬ë¦¬ë¸Œì˜' not in features and 'keyword_ì„¸ì¼' not in features:
            missing_keywords.append("'ì˜¬ë¦¬ë¸Œì˜' ë˜ëŠ” 'ì„¸ì¼'")
        if 'keyword_ë‚´ëˆë‚´ì‚°' not in features:
            missing_keywords.append("'ë‚´ëˆë‚´ì‚°'")
        
        if missing_keywords:
            guidelines.append(f"\nğŸ’¡ ì¶”ê°€í•˜ë©´ ì¢‹ì€ í‚¤ì›Œë“œ: {', '.join(missing_keywords)}")
        
        # ì¸ë„¤ì¼ ì¡°ì–¸
        guidelines.append("\nğŸ“¸ ì¸ë„¤ì¼ íŒ: ì–¼êµ´ í´ë¡œì¦ˆì—… + ì œí’ˆ ì´ë¯¸ì§€ ì¡°í•©ì´ í´ë¦­ë¥ ì´ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤.")
        
        # ì—…ë¡œë“œ ì‹œê°„ ì¡°ì–¸
        guidelines.append("\nâ° ìµœì  ì—…ë¡œë“œ ì‹œê°„: ê¸ˆìš”ì¼ ì˜¤í›„ 7-9ì‹œ")
        
        return "\n".join(guidelines)
