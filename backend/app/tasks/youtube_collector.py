"""
ìœ íŠœë¸Œ ë°ì´í„° ìˆ˜ì§‘ê¸°
YouTube Data API v3 ì •ì±…ì„ ì™„ë²½íˆ ì¤€ìˆ˜í•˜ëŠ” ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
"""
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import time
import os

from app.core.config import settings
from app.db.database import SessionLocal
from app.models.models import VideoData

class YouTubeCollector:
    """
    YouTube ë°ì´í„° ìˆ˜ì§‘ê¸°
    
    API ì •ì±… ì¤€ìˆ˜ ì‚¬í•­:
    1. ë°ì´í„° ì €ì¥ ê¸°ê°„: ìµœëŒ€ 30ì¼ (ìë™ ì‚­ì œ/ê°±ì‹ )
    2. í• ë‹¹ëŸ‰ ê´€ë¦¬: í•˜ë£¨ 10,000 í¬ì¸íŠ¸ ì œí•œ
    3. ì¼ê´„ ì²˜ë¦¬: ìµœëŒ€ 50ê°œì”© ë¬¶ì–´ì„œ í˜¸ì¶œ
    4. ì—ëŸ¬ ì²˜ë¦¬: ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©
    """
    
    def __init__(self):
        self.api_key = settings.YOUTUBE_API_KEY
        if not self.api_key:
            raise ValueError("YOUTUBE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.youtube = build('youtube', 'v3', developerKey=self.api_key)
        self.quota_used = 0
        self.quota_limit = settings.YOUTUBE_QUOTA_LIMIT
    
    def search_beauty_videos(self, max_results: int = 50, published_after: Optional[datetime] = None) -> List[str]:
        """
        ë·°í‹° ì¹´í…Œê³ ë¦¬ ì˜ìƒ ê²€ìƒ‰
        
        Args:
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 50)
            published_after: ì´ ë‚ ì§œ ì´í›„ ì—…ë¡œë“œëœ ì˜ìƒë§Œ ê²€ìƒ‰
        
        Returns:
            ì˜ìƒ ID ë¦¬ìŠ¤íŠ¸
        """
        if not published_after:
            # ê¸°ë³¸ê°’: ìµœê·¼ 7ì¼
            published_after = datetime.now() - timedelta(days=7)
        
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ (ë·°í‹° ê´€ë ¨ í‚¤ì›Œë“œ)
            search_query = "ë·°í‹° ë©”ì´í¬ì—… OR ì˜¬ë¦¬ë¸Œì˜ OR í™”ì¥í’ˆ ë¦¬ë·°"
            
            request = self.youtube.search().list(
                part="id",
                q=search_query,
                type="video",
                regionCode="KR",
                relevanceLanguage="ko",
                maxResults=min(max_results, 50),
                publishedAfter=published_after.isoformat() + "Z",
                order="viewCount"  # ì¡°íšŒìˆ˜ ìˆœ
            )
            
            response = request.execute()
            self.quota_used += 100  # search.list = 100 í¬ì¸íŠ¸
            
            video_ids = [item['id']['videoId'] for item in response.get('items', [])]
            
            print(f"âœ… {len(video_ids)}ê°œ ì˜ìƒ ê²€ìƒ‰ ì™„ë£Œ (í• ë‹¹ëŸ‰ ì‚¬ìš©: {self.quota_used}/{self.quota_limit})")
            
            return video_ids
            
        except HttpError as e:
            print(f"âŒ YouTube API ì˜¤ë¥˜: {e}")
            return []
    
    def get_video_details(self, video_ids: List[str]) -> List[Dict]:
        """
        ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ì¼ê´„ ì²˜ë¦¬)
        
        Args:
            video_ids: ì˜ìƒ ID ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 50ê°œ)
        
        Returns:
            ì˜ìƒ ìƒì„¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if not video_ids:
            return []
        
        # 50ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬ (API ì œí•œ)
        batch_size = 50
        all_videos = []
        
        for i in range(0, len(video_ids), batch_size):
            batch = video_ids[i:i+batch_size]
            
            try:
                request = self.youtube.videos().list(
                    part="snippet,statistics,contentDetails",
                    id=",".join(batch)
                )
                
                response = request.execute()
                self.quota_used += 1  # videos.list = 1 í¬ì¸íŠ¸
                
                for item in response.get('items', []):
                    video_data = self._parse_video_item(item)
                    all_videos.append(video_data)
                
                print(f"âœ… {len(batch)}ê°œ ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì™„ë£Œ (í• ë‹¹ëŸ‰: {self.quota_used}/{self.quota_limit})")
                
                # API í˜¸ì¶œ ê°„ ì§§ì€ ëŒ€ê¸° (Rate Limiting ë°©ì§€)
                time.sleep(0.1)
                
            except HttpError as e:
                print(f"âŒ ì˜ìƒ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
                # ì§€ìˆ˜ ë°±ì˜¤í”„: ì—ëŸ¬ ë°œìƒ ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                time.sleep(2)
        
        return all_videos
    
    def _parse_video_item(self, item: Dict) -> Dict:
        """
        API ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
        """
        snippet = item['snippet']
        statistics = item.get('statistics', {})
        content_details = item.get('contentDetails', {})
        
        # ISO 8601 durationì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
        duration = self._parse_duration(content_details.get('duration', 'PT0S'))
        
        return {
            'video_id': item['id'],
            'channel_id': snippet['channelId'],
            'title': snippet['title'],
            'description': snippet.get('description', ''),
            'tags': snippet.get('tags', []),
            'view_count': int(statistics.get('viewCount', 0)),
            'like_count': int(statistics.get('likeCount', 0)),
            'comment_count': int(statistics.get('commentCount', 0)),
            'duration': duration,
            'published_at': datetime.fromisoformat(snippet['publishedAt'].replace('Z', '+00:00')),
            'thumbnail_url': snippet['thumbnails']['high']['url']
        }
    
    def _parse_duration(self, duration_str: str) -> int:
        """
        ISO 8601 duration (ì˜ˆ: PT15M33S)ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
        """
        import re
        match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration_str)
        if not match:
            return 0
        
        hours = int(match.group(1) or 0)
        minutes = int(match.group(2) or 0)
        seconds = int(match.group(3) or 0)
        
        return hours * 3600 + minutes * 60 + seconds
    
    def save_to_database(self, videos: List[Dict]):
        """
        ìˆ˜ì§‘í•œ ì˜ìƒ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        """
        db = SessionLocal()
        
        try:
            for video in videos:
                # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                existing = db.query(VideoData).filter(
                    VideoData.video_id == video['video_id']
                ).first()
                
                if existing:
                    # ì—…ë°ì´íŠ¸ (í†µê³„ ì •ë³´ ê°±ì‹ )
                    existing.view_count = video['view_count']
                    existing.like_count = video['like_count']
                    existing.comment_count = video['comment_count']
                    existing.updated_at = datetime.now()
                else:
                    # ìƒˆ ë°ì´í„° ì‚½ì…
                    new_video = VideoData(**video)
                    db.add(new_video)
            
            db.commit()
            print(f"âœ… {len(videos)}ê°œ ì˜ìƒ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            db.rollback()
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")
        finally:
            db.close()
    
    def cleanup_old_data(self):
        """
        30ì¼ ì´ìƒ ì§€ë‚œ ë°ì´í„° ì‚­ì œ (API ì •ì±… ì¤€ìˆ˜)
        """
        db = SessionLocal()
        
        try:
            cutoff_date = datetime.now() - timedelta(days=settings.DATA_RETENTION_DAYS)
            
            deleted_count = db.query(VideoData).filter(
                VideoData.updated_at < cutoff_date
            ).delete()
            
            db.commit()
            print(f"âœ… {deleted_count}ê°œì˜ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ ì™„ë£Œ (30ì¼ ì •ì±… ì¤€ìˆ˜)")
            
        except Exception as e:
            db.rollback()
            print(f"âŒ ë°ì´í„° ì •ë¦¬ ì˜¤ë¥˜: {e}")
        finally:
            db.close()
    
    def run_daily_collection(self):
        """
        ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—… (Cron Jobì—ì„œ í˜¸ì¶œ)
        """
        print("=" * 50)
        print(f"ğŸš€ ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {datetime.now()}")
        print("=" * 50)
        
        # 1. ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
        self.cleanup_old_data()
        
        # 2. ìµœê·¼ 7ì¼ ì˜ìƒ ê²€ìƒ‰
        video_ids = self.search_beauty_videos(max_results=50)
        
        if not video_ids:
            print("âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 3. ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        videos = self.get_video_details(video_ids)
        
        # 4. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if videos:
            self.save_to_database(videos)
        
        print("=" * 50)
        print(f"âœ… ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"   - ìˆ˜ì§‘ ì˜ìƒ: {len(videos)}ê°œ")
        print(f"   - í• ë‹¹ëŸ‰ ì‚¬ìš©: {self.quota_used}/{self.quota_limit}")
        print("=" * 50)


# CLI ì‹¤í–‰ìš©
if __name__ == "__main__":
    collector = YouTubeCollector()
    collector.run_daily_collection()
